{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание среды проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://n-ws-f21jf.s3pd02.sbercloud.ru/b-ws-f21jf-ny6/FBC2/titw_sberidp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create -n ocr\n",
    "conda activate ocr\n",
    "conda install pytorch torchvision torchaudio cudatoolkit=11.6 -c pytorch -c conda-forge\n",
    "pip install jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openmim\n",
    "mim install mmcv-full\n",
    "mim install mmdet\n",
    "# Датасет с AIJ\n",
    "wget https://n-ws-f21jf.s3pd02.sbercloud.ru/b-ws-f21jf-ny6/FBC2/titw_sberidp.zip\n",
    "git clone https://github.com/open-mmlab/mmocr.git\n",
    "# Файлы с кодом должны быть в этой же папке\n",
    "cd mmocr\n",
    "pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Играюсь с MMOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?MMOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmocr.utils.ocr import MMOCR\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr = MMOCR(det='DBPP_r50', det_config='', recog='ABINet', recog_config='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?MMOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmocr.utils.ocr import MMOCR\n",
    "import torch\n",
    "\n",
    "# Load models into memory\n",
    "ocr = MMOCR(det='TextSnake', recog=None)\n",
    "\n",
    "# Inference\n",
    "results = ocr.readtext('demo/demo_text_det.jpg', output='demo/', export='demo/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmocr.utils.ocr import MMOCR\n",
    "\n",
    "# Load models into memory\n",
    "ocr = MMOCR(det=None, recog='CRNN_TPS')\n",
    "\n",
    "# Inference\n",
    "results = ocr.readtext(%INPUT_FOLDER_PATH%, output = %OUTPUT_FOLDER_PATH%, batch_mode=True, single_batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmocr.utils.ocr import MMOCR\n",
    "\n",
    "# Load models into memory\n",
    "ocr = MMOCR()\n",
    "\n",
    "# Inference\n",
    "results = ocr.readtext('demo/demo_text_ocr.jpg', print_result=True, imshow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmocr.utils.ocr import MMOCR\n",
    "mmocr = MMOCR(det='TextSnake', recog='SAR')\n",
    "results = mmocr.readtext('demo/demo_text_ocr.jpg', print_result=True, output='outputs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmocr/textdet/textsnake/textsnake_r50_fpn_unet_1200e_ctw1500-27f65b64.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmocr/textrecog/sar/sar_r31_parallel_decoder_academic-dba3a4a3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/shared_storage/Python/Notebooks/Non-Braille/mmocr/mmocr/apis/inference.py:50: UserWarning: Class names are not saved in the checkpoint's meta data, use COCO classes by default.\n",
      "  warnings.warn('Class names are not saved in the checkpoint\\'s '\n",
      "/home/mat/miniconda3/envs/ocr/lib/python3.9/site-packages/mmdet/datasets/utils.py:66: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  warnings.warn(\n",
      "/mnt/shared_storage/Python/Notebooks/Non-Braille/mmocr/mmocr/models/textdet/postprocess/utils.py:51: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  canvas = canvas[1:h + 1, 1:w + 1].astype(np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': '00001', 'text': ['CONVERSITY', 'III', 'O', 'I\"', 'Q:', '/in', 'is', 'simply', 'ODGER', 'O.', 'Ceeseen', 'MHAUL', 'KOPE', 'MOTOROLOGIC', '0', 'Multane']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmocr.utils.ocr import MMOCR\n",
    "mmocr = MMOCR(det='TextSnake', recog='SAR')\n",
    "results = mmocr.readtext('../mmocr/ocr-app/static/images/00001.jpg', print_result=True, output='outputs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " text = ' '.join(results[0]['text'])\n",
    " text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmocr.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "import matplotlib.pyplot as plt\n",
    "import mmcv\n",
    "predicted_img = mmcv.imread('outputs/out_demo_text_ocr.png')\n",
    "plt.figure(figsize=(9, 16))\n",
    "plt.imshow(mmcv.bgr2rgb(predicted_img))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mat/miniconda3/envs/ocr/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "# import cv2\n",
    "\n",
    "import torch\n",
    "\n",
    "from mmocr.utils.ocr import MMOCR\n",
    "import mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeplake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install deeplake flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "ds = deeplake.load(\"hub://activeloop/coco-text-train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog_path = '../titw_dataset/real-world data/images/'\n",
    "# synth_data_path = '../titw_dataset/synthetic data/images_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_recog_json = '../titw_dataset/real-world data/input_titw.json'\n",
    "output_recog_json = '../titw_dataset/real-world data/output_titw.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_synth_input_data_json = '../titw_dataset/synthetic data/train/input_train.json'\n",
    "# train_synth_output_data_json = '../titw_dataset/synthetic data/train/output_train.json'\n",
    "\n",
    "# val_synth_input_data_json = '../titw_dataset/synthetic data/val/input_val.json'\n",
    "# val_synth_output_data_json = '../titw_dataset/synthetic data/val/output_val.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_recog_json) as file:\n",
    "    input_data = json.load(file)\n",
    "\n",
    "with open(output_recog_json) as file:\n",
    "    output_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(train_synth_input_data_json) as file:\n",
    "#     train_synth_input_data = json.load(file)\n",
    "\n",
    "# with open(train_synth_output_data_json) as file:\n",
    "#     train_synth_output_data = json.load(file)\n",
    "    \n",
    "# with open(val_synth_input_data_json) as file:\n",
    "#     val_synth_input_data = json.load(file)\n",
    "\n",
    "# with open(val_synth_output_data_json) as file:\n",
    "#     val_synth_output_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(input_data.items())[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data['20000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_data['content'] == 'coffe \\\\/n t me'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in list(output_data.items())[10000]:\n",
    "    # print(item[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирую модели детекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmocr.utils.ocr import MMOCR\n",
    "import torch\n",
    "\n",
    "# Load models into memory\n",
    "# ocr = MMOCR(det='DBPP_r50', recog=None)\n",
    "# ocr = MMOCR(det='PS_CTW', recog=None)\n",
    "ocr = MMOCR(det='PANet_CTW', recog=None)\n",
    "\n",
    "num_of_images = 100\n",
    "rows = 100\n",
    "columns = 1\n",
    "    \n",
    "\n",
    "fig = plt.figure()\n",
    "not_detected = 0\n",
    "\n",
    "\n",
    "for num in range(num_of_images):\n",
    "    try:\n",
    "        results = ocr.readtext('../titw_dataset/real-world data/images/' + str(num) + '.jpg', output='../titw_dataset/real-world data/',\n",
    "                            export='../titw_dataset/real-world data/images/')\n",
    "\n",
    "        fig.add_subplot(rows, columns, num+1)\n",
    "        plt.axis('off')\n",
    "        predicted_img = mmcv.imread('../titw_dataset/real-world data/out_' + str(num) + '.png')\n",
    "        plt.imshow(mmcv.bgr2rgb(predicted_img))\n",
    "        # plt.show()\n",
    "    except FileNotFoundError:\n",
    "        # print('NOTHING HAS BEEN DETECTED')\n",
    "        not_detected += 1\n",
    "\n",
    "plt.show()\n",
    "model_name = str(ocr.detect_model)[:str(ocr.detect_model).index('(')]\n",
    "print(model_name + ': ' + str(not_detected)+'/'+str(num_of_images) + ' not detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmocr.utils.ocr import MMOCR\n",
    "import torch\n",
    "\n",
    "# Load models into memory\n",
    "# ocr = MMOCR(det='DBPP_r50', recog=None)\n",
    "ocr = MMOCR(det='PS_CTW', recog=None)\n",
    "# ocr = MMOCR(det='PANet_CTW', recog=None)\n",
    "\n",
    "num_of_images = 100\n",
    "rows = 100\n",
    "columns = 1\n",
    "    \n",
    "\n",
    "fig = plt.figure()\n",
    "not_detected = 0\n",
    "\n",
    "\n",
    "for num in range(num_of_images):\n",
    "    try:\n",
    "        results = ocr.readtext('../titw_dataset/real-world data/images/' + str(num) + '.jpg', output='../titw_dataset/real-world data/',\n",
    "                            export='../titw_dataset/real-world data/images/')\n",
    "\n",
    "        fig.add_subplot(rows, columns, num+1)\n",
    "        plt.axis('off')\n",
    "        predicted_img = mmcv.imread('../titw_dataset/real-world data/out_' + str(num) + '.png')\n",
    "        # plt.imshow(mmcv.bgr2rgb(predicted_img))\n",
    "        # plt.show()\n",
    "    except FileNotFoundError:\n",
    "        # print('NOTHING HAS BEEN DETECTED')\n",
    "        not_detected += 1\n",
    "\n",
    "plt.show()\n",
    "model_name = str(ocr.detect_model)[:str(ocr.detect_model).index('(')]\n",
    "print(model_name + ': ' + str(not_detected)+'/'+str(num_of_images) + ' not detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmocr.datasets import text_det_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = text_det_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmocr.utils.ocr import MMOCR\n",
    "import torch\n",
    "\n",
    "# Load models into memory\n",
    "ocr = MMOCR(det='DBPP_r50', recog=None)\n",
    "# ocr = MMOCR(det='PS_CTW', recog=None)\n",
    "# ocr = MMOCR(det='PANet_CTW', recog=None)\n",
    "\n",
    "num_of_images = 99\n",
    "rows = 100\n",
    "columns = 1    \n",
    "\n",
    "fig = plt.figure()\n",
    "not_detected = 0\n",
    "\n",
    "\n",
    "for num in range(num_of_images):\n",
    "    try:\n",
    "        # results = ocr.readtext('../titw_dataset/real-world data/images/' + str(num) + '.jpg', output='../titw_dataset/real-world data/',\n",
    "        #                     export='../titw_dataset/real-world data/images/')\\\n",
    "        if num < 10:\n",
    "            results = ocr.readtext('../Train/train/0000' + str(num) + '.jpg', output='../Outputs/',\n",
    "                            export='../Outputs/')\n",
    "            print('../Train/train/0000' + str(num) + '.jpg')\n",
    "        else:\n",
    "            results = ocr.readtext('../Train/train/000' + str(num) + '.jpg', output='../Outputs/',\n",
    "                            export='../Outputs/')\n",
    "            print('../Train/train/000' + str(num) + '.jpg')\n",
    "        \n",
    "\n",
    "        fig.add_subplot(rows, columns, num+1)\n",
    "        plt.axis('off')\n",
    "        # predicted_img = mmcv.imread('../titw_dataset/real-world data/out_' + str(num) + '.png')\n",
    "        predicted_img = mmcv.imread('../Outputs/out_000' + str(num) + '.png')\n",
    "        # plt.imshow(mmcv.bgr2rgb(predicted_img))\n",
    "        # plt.show()\n",
    "    except FileNotFoundError:\n",
    "        # print('../Train/train/000' + str(num) + '.jpg')\n",
    "        # print('NOTHING HAS BEEN DETECTED')\n",
    "        not_detected += 1\n",
    "\n",
    "plt.show()\n",
    "model_name = str(ocr.detect_model)[:str(ocr.detect_model).index('(')]\n",
    "print(model_name + ': ' + str(not_detected)+'/'+str(num_of_images) + ' not detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmocr.utils.ocr import MMOCR\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load models into memory\n",
    "ocr = MMOCR(det='DBPP_r50', recog=None)\n",
    "# ocr = MMOCR(det='PS_CTW', recog=None)\n",
    "# ocr = MMOCR(det='PANet_CTW', recog=None)\n",
    "\n",
    "num_of_images = 25\n",
    "rows = 25\n",
    "columns = 1\n",
    "    \n",
    "\n",
    "fig = plt.figure()\n",
    "not_detected = 0\n",
    "\n",
    "\n",
    "for num in range(num_of_images):\n",
    "    try:\n",
    "        results = ocr.readtext('../titw_dataset/synthetic data/images_train/' + str(num) + '.jpg', output='../titw_dataset/synthetic data/train/',\n",
    "                            export='../titw_dataset/synthetic data/train/')\n",
    "\n",
    "        fig.add_subplot(rows, columns, num+1)\n",
    "        plt.axis('off')\n",
    "        predicted_img = mmcv.imread('../titw_dataset/synthetic data/train/out_' + str(num) + '.png')\n",
    "        # plt.imshow(mmcv.bgr2rgb(predicted_img))\n",
    "        # plt.show()\n",
    "    except FileNotFoundError:\n",
    "        # print('NOTHING HAS BEEN DETECTED')\n",
    "        not_detected += 1\n",
    "\n",
    "plt.show()\n",
    "model_name = str(ocr.detect_model)[:str(ocr.detect_model).index('(')]\n",
    "print(model_name + ': ' + str(not_detected)+'/'+str(num_of_images) + ' not detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_img = mmcv.imread('/mnt/shared_storage/Python/Notebooks/Non-Braille/titw_dataset/synthetic data/train/' + 'out_1.png')\n",
    "Image.fromarray(mmcv.bgr2rgb(predicted_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_img = mmcv.imread(synth_data_path + '/500.jpg')\n",
    "Image.fromarray(mmcv.bgr2rgb(predicted_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Верю в \n",
    "1. DBPP_r50\n",
    "2. FCE_IC15\n",
    "3. FCE_CTW_DCNv2\n",
    "4. PSENet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Верю в \n",
    "1. ABINet\n",
    "2. MASTER\n",
    "3. RobustScanner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = mmcv.Config.fromfile('configs/textrecog/abinet/abinet_academic.py')\n",
    "# cfg = mmcv.Config.fromfile('configs/textrecog/master/master_r31_12e_ST_MJ_SA.py')\n",
    "# cfg = mmcv.Config.fromfile('configs/textrecog/master/master_toy_dataset.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "optimizer = dict(type='Adam', lr=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    step=[16, 18],\n",
      "    warmup='linear',\n",
      "    warmup_iters=1,\n",
      "    warmup_ratio=0.001,\n",
      "    warmup_by_epoch=True)\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=20)\n",
      "checkpoint_config = dict(interval=1)\n",
      "img_norm_cfg = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='ResizeOCR',\n",
      "        height=32,\n",
      "        min_width=128,\n",
      "        max_width=128,\n",
      "        keep_aspect_ratio=False,\n",
      "        width_downsample_ratio=0.25),\n",
      "    dict(\n",
      "        type='RandomWrapper',\n",
      "        p=0.5,\n",
      "        transforms=[\n",
      "            dict(\n",
      "                type='OneOfWrapper',\n",
      "                transforms=[\n",
      "                    dict(type='RandomRotateTextDet', max_angle=15),\n",
      "                    dict(\n",
      "                        type='TorchVisionWrapper',\n",
      "                        op='RandomAffine',\n",
      "                        degrees=15,\n",
      "                        translate=(0.3, 0.3),\n",
      "                        scale=(0.5, 2.0),\n",
      "                        shear=(-45, 45)),\n",
      "                    dict(\n",
      "                        type='TorchVisionWrapper',\n",
      "                        op='RandomPerspective',\n",
      "                        distortion_scale=0.5,\n",
      "                        p=1)\n",
      "                ])\n",
      "        ]),\n",
      "    dict(\n",
      "        type='RandomWrapper',\n",
      "        p=0.25,\n",
      "        transforms=[\n",
      "            dict(type='PyramidRescale'),\n",
      "            dict(\n",
      "                type='Albu',\n",
      "                transforms=[\n",
      "                    dict(type='GaussNoise', var_limit=(20, 20), p=0.5),\n",
      "                    dict(type='MotionBlur', blur_limit=6, p=0.5)\n",
      "                ])\n",
      "        ]),\n",
      "    dict(\n",
      "        type='RandomWrapper',\n",
      "        p=0.25,\n",
      "        transforms=[\n",
      "            dict(\n",
      "                type='TorchVisionWrapper',\n",
      "                op='ColorJitter',\n",
      "                brightness=0.5,\n",
      "                saturation=0.5,\n",
      "                contrast=0.5,\n",
      "                hue=0.1)\n",
      "        ]),\n",
      "    dict(type='ToTensorOCR'),\n",
      "    dict(\n",
      "        type='NormalizeOCR',\n",
      "        mean=[0.485, 0.456, 0.406],\n",
      "        std=[0.229, 0.224, 0.225]),\n",
      "    dict(\n",
      "        type='Collect',\n",
      "        keys=['img'],\n",
      "        meta_keys=[\n",
      "            'filename', 'ori_shape', 'img_shape', 'text', 'valid_ratio',\n",
      "            'resize_shape'\n",
      "        ])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiRotateAugOCR',\n",
      "        rotate_degrees=[0, 90, 270],\n",
      "        transforms=[\n",
      "            dict(\n",
      "                type='ResizeOCR',\n",
      "                height=32,\n",
      "                min_width=128,\n",
      "                max_width=128,\n",
      "                keep_aspect_ratio=False,\n",
      "                width_downsample_ratio=0.25),\n",
      "            dict(type='ToTensorOCR'),\n",
      "            dict(\n",
      "                type='NormalizeOCR',\n",
      "                mean=[0.485, 0.456, 0.406],\n",
      "                std=[0.229, 0.224, 0.225]),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                keys=['img'],\n",
      "                meta_keys=[\n",
      "                    'filename', 'ori_shape', 'img_shape', 'valid_ratio',\n",
      "                    'resize_shape', 'img_norm_cfg', 'ori_filename'\n",
      "                ])\n",
      "        ])\n",
      "]\n",
      "num_chars = 37\n",
      "max_seq_len = 26\n",
      "label_convertor = dict(\n",
      "    type='ABIConvertor',\n",
      "    dict_type='DICT36',\n",
      "    with_unknown=False,\n",
      "    with_padding=False,\n",
      "    lower=True,\n",
      "    max_seq_len=26)\n",
      "model = dict(\n",
      "    type='ABINet',\n",
      "    backbone=dict(type='ResNetABI'),\n",
      "    encoder=dict(\n",
      "        type='ABIVisionModel',\n",
      "        encoder=dict(\n",
      "            type='TransformerEncoder',\n",
      "            n_layers=3,\n",
      "            n_head=8,\n",
      "            d_model=512,\n",
      "            d_inner=2048,\n",
      "            dropout=0.1,\n",
      "            max_len=256),\n",
      "        decoder=dict(\n",
      "            type='ABIVisionDecoder',\n",
      "            in_channels=512,\n",
      "            num_channels=64,\n",
      "            attn_height=8,\n",
      "            attn_width=32,\n",
      "            attn_mode='nearest',\n",
      "            use_result='feature',\n",
      "            num_chars=37,\n",
      "            max_seq_len=26,\n",
      "            init_cfg=dict(type='Xavier', layer='Conv2d'))),\n",
      "    decoder=dict(\n",
      "        type='ABILanguageDecoder',\n",
      "        d_model=512,\n",
      "        n_head=8,\n",
      "        d_inner=2048,\n",
      "        n_layers=4,\n",
      "        dropout=0.1,\n",
      "        detach_tokens=True,\n",
      "        use_self_attn=False,\n",
      "        pad_idx=36,\n",
      "        num_chars=37,\n",
      "        max_seq_len=26,\n",
      "        init_cfg=None),\n",
      "    fuser=dict(\n",
      "        type='ABIFuser',\n",
      "        d_model=512,\n",
      "        num_chars=37,\n",
      "        init_cfg=None,\n",
      "        max_seq_len=26),\n",
      "    loss=dict(\n",
      "        type='ABILoss',\n",
      "        enc_weight=1.0,\n",
      "        dec_weight=1.0,\n",
      "        fusion_weight=1.0,\n",
      "        num_classes=37),\n",
      "    label_convertor=dict(\n",
      "        type='ABIConvertor',\n",
      "        dict_type='DICT36',\n",
      "        with_unknown=False,\n",
      "        with_padding=False,\n",
      "        lower=True,\n",
      "        max_seq_len=26),\n",
      "    max_seq_len=26,\n",
      "    iter_size=3)\n",
      "train_root = 'data/mixture'\n",
      "train_img_prefix1 = 'data/mixture/Syn90k/mnt/ramdisk/max/90kDICT32px'\n",
      "train_ann_file1 = 'data/mixture/Syn90k/label.lmdb'\n",
      "train1 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/Syn90k/mnt/ramdisk/max/90kDICT32px',\n",
      "    ann_file='data/mixture/Syn90k/label.lmdb',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='lmdb',\n",
      "        parser=dict(type='LineJsonParser', keys=['filename', 'text'])),\n",
      "    pipeline=None,\n",
      "    test_mode=False)\n",
      "train_img_prefix2 = 'data/mixture/SynthText/synthtext/SynthText_patch_horizontal'\n",
      "train_ann_file2 = 'data/mixture/SynthText/alphanumeric_label.lmdb'\n",
      "train2 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/SynthText/synthtext/SynthText_patch_horizontal',\n",
      "    ann_file='data/mixture/SynthText/alphanumeric_label.lmdb',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='lmdb',\n",
      "        parser=dict(type='LineJsonParser', keys=['filename', 'text'])),\n",
      "    pipeline=None,\n",
      "    test_mode=False)\n",
      "train_list = [\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix='data/mixture/Syn90k/mnt/ramdisk/max/90kDICT32px',\n",
      "        ann_file='data/mixture/Syn90k/label.lmdb',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='lmdb',\n",
      "            parser=dict(type='LineJsonParser', keys=['filename', 'text'])),\n",
      "        pipeline=None,\n",
      "        test_mode=False),\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix=\n",
      "        'data/mixture/SynthText/synthtext/SynthText_patch_horizontal',\n",
      "        ann_file='data/mixture/SynthText/alphanumeric_label.lmdb',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='lmdb',\n",
      "            parser=dict(type='LineJsonParser', keys=['filename', 'text'])),\n",
      "        pipeline=None,\n",
      "        test_mode=False)\n",
      "]\n",
      "test_root = 'data/mixture'\n",
      "test_img_prefix1 = 'data/mixture/IIIT5K/'\n",
      "test_img_prefix2 = 'data/mixture/svt/'\n",
      "test_img_prefix3 = 'data/mixture/icdar_2013/'\n",
      "test_img_prefix4 = 'data/mixture/icdar_2015/'\n",
      "test_img_prefix5 = 'data/mixture/svtp/'\n",
      "test_img_prefix6 = 'data/mixture/ct80/'\n",
      "test_ann_file1 = 'data/mixture/IIIT5K/test_label.txt'\n",
      "test_ann_file2 = 'data/mixture/svt/test_label.txt'\n",
      "test_ann_file3 = 'data/mixture/icdar_2013/test_label_1015.txt'\n",
      "test_ann_file4 = 'data/mixture/icdar_2015/test_label.txt'\n",
      "test_ann_file5 = 'data/mixture/svtp/test_label.txt'\n",
      "test_ann_file6 = 'data/mixture/ct80/test_label.txt'\n",
      "test1 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/IIIT5K/',\n",
      "    ann_file='data/mixture/IIIT5K/test_label.txt',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='txt',\n",
      "        parser=dict(\n",
      "            type='LineStrParser',\n",
      "            keys=['filename', 'text'],\n",
      "            keys_idx=[0, 1],\n",
      "            separator=' ')),\n",
      "    pipeline=None,\n",
      "    test_mode=True)\n",
      "test2 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/svt/',\n",
      "    ann_file='data/mixture/svt/test_label.txt',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='txt',\n",
      "        parser=dict(\n",
      "            type='LineStrParser',\n",
      "            keys=['filename', 'text'],\n",
      "            keys_idx=[0, 1],\n",
      "            separator=' ')),\n",
      "    pipeline=None,\n",
      "    test_mode=True)\n",
      "test3 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/icdar_2013/',\n",
      "    ann_file='data/mixture/icdar_2013/test_label_1015.txt',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='txt',\n",
      "        parser=dict(\n",
      "            type='LineStrParser',\n",
      "            keys=['filename', 'text'],\n",
      "            keys_idx=[0, 1],\n",
      "            separator=' ')),\n",
      "    pipeline=None,\n",
      "    test_mode=True)\n",
      "test4 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/icdar_2015/',\n",
      "    ann_file='data/mixture/icdar_2015/test_label.txt',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='txt',\n",
      "        parser=dict(\n",
      "            type='LineStrParser',\n",
      "            keys=['filename', 'text'],\n",
      "            keys_idx=[0, 1],\n",
      "            separator=' ')),\n",
      "    pipeline=None,\n",
      "    test_mode=True)\n",
      "test5 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/svtp/',\n",
      "    ann_file='data/mixture/svtp/test_label.txt',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='txt',\n",
      "        parser=dict(\n",
      "            type='LineStrParser',\n",
      "            keys=['filename', 'text'],\n",
      "            keys_idx=[0, 1],\n",
      "            separator=' ')),\n",
      "    pipeline=None,\n",
      "    test_mode=True)\n",
      "test6 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/ct80/',\n",
      "    ann_file='data/mixture/ct80/test_label.txt',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='txt',\n",
      "        parser=dict(\n",
      "            type='LineStrParser',\n",
      "            keys=['filename', 'text'],\n",
      "            keys_idx=[0, 1],\n",
      "            separator=' ')),\n",
      "    pipeline=None,\n",
      "    test_mode=True)\n",
      "test_list = [\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix='data/mixture/IIIT5K/',\n",
      "        ann_file='data/mixture/IIIT5K/test_label.txt',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='txt',\n",
      "            parser=dict(\n",
      "                type='LineStrParser',\n",
      "                keys=['filename', 'text'],\n",
      "                keys_idx=[0, 1],\n",
      "                separator=' ')),\n",
      "        pipeline=None,\n",
      "        test_mode=True),\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix='data/mixture/svt/',\n",
      "        ann_file='data/mixture/svt/test_label.txt',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='txt',\n",
      "            parser=dict(\n",
      "                type='LineStrParser',\n",
      "                keys=['filename', 'text'],\n",
      "                keys_idx=[0, 1],\n",
      "                separator=' ')),\n",
      "        pipeline=None,\n",
      "        test_mode=True),\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix='data/mixture/icdar_2013/',\n",
      "        ann_file='data/mixture/icdar_2013/test_label_1015.txt',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='txt',\n",
      "            parser=dict(\n",
      "                type='LineStrParser',\n",
      "                keys=['filename', 'text'],\n",
      "                keys_idx=[0, 1],\n",
      "                separator=' ')),\n",
      "        pipeline=None,\n",
      "        test_mode=True),\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix='data/mixture/icdar_2015/',\n",
      "        ann_file='data/mixture/icdar_2015/test_label.txt',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='txt',\n",
      "            parser=dict(\n",
      "                type='LineStrParser',\n",
      "                keys=['filename', 'text'],\n",
      "                keys_idx=[0, 1],\n",
      "                separator=' ')),\n",
      "        pipeline=None,\n",
      "        test_mode=True),\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix='data/mixture/svtp/',\n",
      "        ann_file='data/mixture/svtp/test_label.txt',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='txt',\n",
      "            parser=dict(\n",
      "                type='LineStrParser',\n",
      "                keys=['filename', 'text'],\n",
      "                keys_idx=[0, 1],\n",
      "                separator=' ')),\n",
      "        pipeline=None,\n",
      "        test_mode=True),\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix='data/mixture/ct80/',\n",
      "        ann_file='data/mixture/ct80/test_label.txt',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='txt',\n",
      "            parser=dict(\n",
      "                type='LineStrParser',\n",
      "                keys=['filename', 'text'],\n",
      "                keys_idx=[0, 1],\n",
      "                separator=' ')),\n",
      "        pipeline=None,\n",
      "        test_mode=True)\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=192,\n",
      "    workers_per_gpu=8,\n",
      "    val_dataloader=dict(samples_per_gpu=1),\n",
      "    test_dataloader=dict(samples_per_gpu=1),\n",
      "    train=dict(\n",
      "        type='UniformConcatDataset',\n",
      "        datasets=[\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/Syn90k/mnt/ramdisk/max/90kDICT32px',\n",
      "                ann_file='data/mixture/Syn90k/label.lmdb',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='lmdb',\n",
      "                    parser=dict(\n",
      "                        type='LineJsonParser', keys=['filename', 'text'])),\n",
      "                pipeline=None,\n",
      "                test_mode=False),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix=\n",
      "                'data/mixture/SynthText/synthtext/SynthText_patch_horizontal',\n",
      "                ann_file='data/mixture/SynthText/alphanumeric_label.lmdb',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='lmdb',\n",
      "                    parser=dict(\n",
      "                        type='LineJsonParser', keys=['filename', 'text'])),\n",
      "                pipeline=None,\n",
      "                test_mode=False)\n",
      "        ],\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='ResizeOCR',\n",
      "                height=32,\n",
      "                min_width=128,\n",
      "                max_width=128,\n",
      "                keep_aspect_ratio=False,\n",
      "                width_downsample_ratio=0.25),\n",
      "            dict(\n",
      "                type='RandomWrapper',\n",
      "                p=0.5,\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        type='OneOfWrapper',\n",
      "                        transforms=[\n",
      "                            dict(type='RandomRotateTextDet', max_angle=15),\n",
      "                            dict(\n",
      "                                type='TorchVisionWrapper',\n",
      "                                op='RandomAffine',\n",
      "                                degrees=15,\n",
      "                                translate=(0.3, 0.3),\n",
      "                                scale=(0.5, 2.0),\n",
      "                                shear=(-45, 45)),\n",
      "                            dict(\n",
      "                                type='TorchVisionWrapper',\n",
      "                                op='RandomPerspective',\n",
      "                                distortion_scale=0.5,\n",
      "                                p=1)\n",
      "                        ])\n",
      "                ]),\n",
      "            dict(\n",
      "                type='RandomWrapper',\n",
      "                p=0.25,\n",
      "                transforms=[\n",
      "                    dict(type='PyramidRescale'),\n",
      "                    dict(\n",
      "                        type='Albu',\n",
      "                        transforms=[\n",
      "                            dict(type='GaussNoise', var_limit=(20, 20), p=0.5),\n",
      "                            dict(type='MotionBlur', blur_limit=6, p=0.5)\n",
      "                        ])\n",
      "                ]),\n",
      "            dict(\n",
      "                type='RandomWrapper',\n",
      "                p=0.25,\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        type='TorchVisionWrapper',\n",
      "                        op='ColorJitter',\n",
      "                        brightness=0.5,\n",
      "                        saturation=0.5,\n",
      "                        contrast=0.5,\n",
      "                        hue=0.1)\n",
      "                ]),\n",
      "            dict(type='ToTensorOCR'),\n",
      "            dict(\n",
      "                type='NormalizeOCR',\n",
      "                mean=[0.485, 0.456, 0.406],\n",
      "                std=[0.229, 0.224, 0.225]),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                keys=['img'],\n",
      "                meta_keys=[\n",
      "                    'filename', 'ori_shape', 'img_shape', 'text',\n",
      "                    'valid_ratio', 'resize_shape'\n",
      "                ])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='UniformConcatDataset',\n",
      "        datasets=[\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/IIIT5K/',\n",
      "                ann_file='data/mixture/IIIT5K/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/svt/',\n",
      "                ann_file='data/mixture/svt/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/icdar_2013/',\n",
      "                ann_file='data/mixture/icdar_2013/test_label_1015.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/icdar_2015/',\n",
      "                ann_file='data/mixture/icdar_2015/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/svtp/',\n",
      "                ann_file='data/mixture/svtp/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/ct80/',\n",
      "                ann_file='data/mixture/ct80/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True)\n",
      "        ],\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiRotateAugOCR',\n",
      "                rotate_degrees=[0, 90, 270],\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        type='ResizeOCR',\n",
      "                        height=32,\n",
      "                        min_width=128,\n",
      "                        max_width=128,\n",
      "                        keep_aspect_ratio=False,\n",
      "                        width_downsample_ratio=0.25),\n",
      "                    dict(type='ToTensorOCR'),\n",
      "                    dict(\n",
      "                        type='NormalizeOCR',\n",
      "                        mean=[0.485, 0.456, 0.406],\n",
      "                        std=[0.229, 0.224, 0.225]),\n",
      "                    dict(\n",
      "                        type='Collect',\n",
      "                        keys=['img'],\n",
      "                        meta_keys=[\n",
      "                            'filename', 'ori_shape', 'img_shape',\n",
      "                            'valid_ratio', 'resize_shape', 'img_norm_cfg',\n",
      "                            'ori_filename'\n",
      "                        ])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='UniformConcatDataset',\n",
      "        datasets=[\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/IIIT5K/',\n",
      "                ann_file='data/mixture/IIIT5K/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/svt/',\n",
      "                ann_file='data/mixture/svt/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/icdar_2013/',\n",
      "                ann_file='data/mixture/icdar_2013/test_label_1015.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/icdar_2015/',\n",
      "                ann_file='data/mixture/icdar_2015/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/svtp/',\n",
      "                ann_file='data/mixture/svtp/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/ct80/',\n",
      "                ann_file='data/mixture/ct80/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True)\n",
      "        ],\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiRotateAugOCR',\n",
      "                rotate_degrees=[0, 90, 270],\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        type='ResizeOCR',\n",
      "                        height=32,\n",
      "                        min_width=128,\n",
      "                        max_width=128,\n",
      "                        keep_aspect_ratio=False,\n",
      "                        width_downsample_ratio=0.25),\n",
      "                    dict(type='ToTensorOCR'),\n",
      "                    dict(\n",
      "                        type='NormalizeOCR',\n",
      "                        mean=[0.485, 0.456, 0.406],\n",
      "                        std=[0.229, 0.224, 0.225]),\n",
      "                    dict(\n",
      "                        type='Collect',\n",
      "                        keys=['img'],\n",
      "                        meta_keys=[\n",
      "                            'filename', 'ori_shape', 'img_shape',\n",
      "                            'valid_ratio', 'resize_shape', 'img_norm_cfg',\n",
      "                            'ori_filename'\n",
      "                        ])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='acc')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'OCRDataset',\n",
       "  'img_prefix': 'data/mixture/Syn90k/mnt/ramdisk/max/90kDICT32px',\n",
       "  'ann_file': 'data/mixture/Syn90k/label.lmdb',\n",
       "  'loader': {'type': 'AnnFileLoader',\n",
       "   'repeat': 1,\n",
       "   'file_format': 'lmdb',\n",
       "   'parser': {'type': 'LineJsonParser', 'keys': ['filename', 'text']}},\n",
       "  'pipeline': None,\n",
       "  'test_mode': False},\n",
       " {'type': 'OCRDataset',\n",
       "  'img_prefix': 'data/mixture/SynthText/synthtext/SynthText_patch_horizontal',\n",
       "  'ann_file': 'data/mixture/SynthText/label.lmdb',\n",
       "  'loader': {'type': 'AnnFileLoader',\n",
       "   'repeat': 1,\n",
       "   'file_format': 'lmdb',\n",
       "   'parser': {'type': 'LineJsonParser', 'keys': ['filename', 'text']}},\n",
       "  'pipeline': None,\n",
       "  'test_mode': False},\n",
       " {'type': 'OCRDataset',\n",
       "  'img_prefix': 'data/mixture/SynthText_Add',\n",
       "  'ann_file': 'data/mixture/SynthText_Add/label.txt',\n",
       "  'loader': {'type': 'AnnFileLoader',\n",
       "   'repeat': 1,\n",
       "   'file_format': 'txt',\n",
       "   'parser': {'type': 'LineStrParser',\n",
       "    'keys': ['filename', 'text'],\n",
       "    'keys_idx': [0, 1],\n",
       "    'separator': ' '}},\n",
       "  'pipeline': None,\n",
       "  'test_mode': False}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        Config\n",
      "\u001b[0;31mString form:\u001b[0m Config (path: configs/textrecog/abinet/abinet_academic.py): {'log_config': {'interval': 5, 'hooks <...> ze_shape', 'img_norm_cfg', 'ori_filename']}]}]}}, 'evaluation': {'interval': 1, 'metric': 'acc'}}\n",
      "\u001b[0;31mLength:\u001b[0m      50\n",
      "\u001b[0;31mFile:\u001b[0m        ~/miniconda3/envs/ocr/lib/python3.9/site-packages/mmcv/utils/config.py\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "A facility for config and config files.\n",
      "\n",
      "It supports common file formats as configs: python/json/yaml. The interface\n",
      "is the same as a dict object and also allows access config values as\n",
      "attributes.\n",
      "\n",
      "Example:\n",
      "    >>> cfg = Config(dict(a=1, b=dict(b1=[0, 1])))\n",
      "    >>> cfg.a\n",
      "    1\n",
      "    >>> cfg.b\n",
      "    {'b1': [0, 1]}\n",
      "    >>> cfg.b.b1\n",
      "    [0, 1]\n",
      "    >>> cfg = Config.fromfile('tests/data/config/a.py')\n",
      "    >>> cfg.filename\n",
      "    \"/home/kchen/projects/mmcv/tests/data/config/a.py\"\n",
      "    >>> cfg.item4\n",
      "    'test'\n",
      "    >>> cfg\n",
      "    \"Config [path: /home/kchen/projects/mmcv/tests/data/config/a.py]: \"\n",
      "    \"{'item1': [1, 2], 'item2': {'a': 0}, 'item3': True, 'item4': 'test'}\"\n"
     ]
    }
   ],
   "source": [
    "?cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "optimizer = dict(type='Adam', lr=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    step=[16, 18],\n",
      "    warmup='linear',\n",
      "    warmup_iters=1,\n",
      "    warmup_ratio=0.001,\n",
      "    warmup_by_epoch=True)\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=20)\n",
      "checkpoint_config = dict(interval=1)\n",
      "img_norm_cfg = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='ResizeOCR',\n",
      "        height=32,\n",
      "        min_width=128,\n",
      "        max_width=128,\n",
      "        keep_aspect_ratio=False,\n",
      "        width_downsample_ratio=0.25),\n",
      "    dict(\n",
      "        type='RandomWrapper',\n",
      "        p=0.5,\n",
      "        transforms=[\n",
      "            dict(\n",
      "                type='OneOfWrapper',\n",
      "                transforms=[\n",
      "                    dict(type='RandomRotateTextDet', max_angle=15),\n",
      "                    dict(\n",
      "                        type='TorchVisionWrapper',\n",
      "                        op='RandomAffine',\n",
      "                        degrees=15,\n",
      "                        translate=(0.3, 0.3),\n",
      "                        scale=(0.5, 2.0),\n",
      "                        shear=(-45, 45)),\n",
      "                    dict(\n",
      "                        type='TorchVisionWrapper',\n",
      "                        op='RandomPerspective',\n",
      "                        distortion_scale=0.5,\n",
      "                        p=1)\n",
      "                ])\n",
      "        ]),\n",
      "    dict(\n",
      "        type='RandomWrapper',\n",
      "        p=0.25,\n",
      "        transforms=[\n",
      "            dict(type='PyramidRescale'),\n",
      "            dict(\n",
      "                type='Albu',\n",
      "                transforms=[\n",
      "                    dict(type='GaussNoise', var_limit=(20, 20), p=0.5),\n",
      "                    dict(type='MotionBlur', blur_limit=6, p=0.5)\n",
      "                ])\n",
      "        ]),\n",
      "    dict(\n",
      "        type='RandomWrapper',\n",
      "        p=0.25,\n",
      "        transforms=[\n",
      "            dict(\n",
      "                type='TorchVisionWrapper',\n",
      "                op='ColorJitter',\n",
      "                brightness=0.5,\n",
      "                saturation=0.5,\n",
      "                contrast=0.5,\n",
      "                hue=0.1)\n",
      "        ]),\n",
      "    dict(type='ToTensorOCR'),\n",
      "    dict(\n",
      "        type='NormalizeOCR',\n",
      "        mean=[0.485, 0.456, 0.406],\n",
      "        std=[0.229, 0.224, 0.225]),\n",
      "    dict(\n",
      "        type='Collect',\n",
      "        keys=['img'],\n",
      "        meta_keys=[\n",
      "            'filename', 'ori_shape', 'img_shape', 'text', 'valid_ratio',\n",
      "            'resize_shape'\n",
      "        ])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiRotateAugOCR',\n",
      "        rotate_degrees=[0, 90, 270],\n",
      "        transforms=[\n",
      "            dict(\n",
      "                type='ResizeOCR',\n",
      "                height=32,\n",
      "                min_width=128,\n",
      "                max_width=128,\n",
      "                keep_aspect_ratio=False,\n",
      "                width_downsample_ratio=0.25),\n",
      "            dict(type='ToTensorOCR'),\n",
      "            dict(\n",
      "                type='NormalizeOCR',\n",
      "                mean=[0.485, 0.456, 0.406],\n",
      "                std=[0.229, 0.224, 0.225]),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                keys=['img'],\n",
      "                meta_keys=[\n",
      "                    'filename', 'ori_shape', 'img_shape', 'valid_ratio',\n",
      "                    'resize_shape', 'img_norm_cfg', 'ori_filename'\n",
      "                ])\n",
      "        ])\n",
      "]\n",
      "num_chars = 37\n",
      "max_seq_len = 26\n",
      "label_convertor = dict(\n",
      "    type='ABIConvertor',\n",
      "    dict_type='DICT36',\n",
      "    with_unknown=False,\n",
      "    with_padding=False,\n",
      "    lower=True,\n",
      "    max_seq_len=26)\n",
      "model = dict(\n",
      "    type='ABINet',\n",
      "    backbone=dict(type='ResNetABI'),\n",
      "    encoder=dict(\n",
      "        type='ABIVisionModel',\n",
      "        encoder=dict(\n",
      "            type='TransformerEncoder',\n",
      "            n_layers=3,\n",
      "            n_head=8,\n",
      "            d_model=512,\n",
      "            d_inner=2048,\n",
      "            dropout=0.1,\n",
      "            max_len=256),\n",
      "        decoder=dict(\n",
      "            type='ABIVisionDecoder',\n",
      "            in_channels=512,\n",
      "            num_channels=64,\n",
      "            attn_height=8,\n",
      "            attn_width=32,\n",
      "            attn_mode='nearest',\n",
      "            use_result='feature',\n",
      "            num_chars=37,\n",
      "            max_seq_len=26,\n",
      "            init_cfg=dict(type='Xavier', layer='Conv2d'))),\n",
      "    decoder=dict(\n",
      "        type='ABILanguageDecoder',\n",
      "        d_model=512,\n",
      "        n_head=8,\n",
      "        d_inner=2048,\n",
      "        n_layers=4,\n",
      "        dropout=0.1,\n",
      "        detach_tokens=True,\n",
      "        use_self_attn=False,\n",
      "        pad_idx=36,\n",
      "        num_chars=37,\n",
      "        max_seq_len=26,\n",
      "        init_cfg=None),\n",
      "    fuser=dict(\n",
      "        type='ABIFuser',\n",
      "        d_model=512,\n",
      "        num_chars=37,\n",
      "        init_cfg=None,\n",
      "        max_seq_len=26),\n",
      "    loss=dict(\n",
      "        type='ABILoss',\n",
      "        enc_weight=1.0,\n",
      "        dec_weight=1.0,\n",
      "        fusion_weight=1.0,\n",
      "        num_classes=37),\n",
      "    label_convertor=dict(\n",
      "        type='ABIConvertor',\n",
      "        dict_type='DICT36',\n",
      "        with_unknown=False,\n",
      "        with_padding=False,\n",
      "        lower=True,\n",
      "        max_seq_len=26),\n",
      "    max_seq_len=26,\n",
      "    iter_size=3)\n",
      "train_root = 'data/mixture'\n",
      "train_img_prefix1 = 'data/mixture/Syn90k/mnt/ramdisk/max/90kDICT32px'\n",
      "train_ann_file1 = 'data/mixture/Syn90k/label.lmdb'\n",
      "train1 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/Syn90k/mnt/ramdisk/max/90kDICT32px',\n",
      "    ann_file='data/mixture/Syn90k/label.lmdb',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='lmdb',\n",
      "        parser=dict(type='LineJsonParser', keys=['filename', 'text'])),\n",
      "    pipeline=None,\n",
      "    test_mode=False)\n",
      "train_img_prefix2 = 'data/mixture/SynthText/synthtext/SynthText_patch_horizontal'\n",
      "train_ann_file2 = 'data/mixture/SynthText/alphanumeric_label.lmdb'\n",
      "train2 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/SynthText/synthtext/SynthText_patch_horizontal',\n",
      "    ann_file='data/mixture/SynthText/alphanumeric_label.lmdb',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='lmdb',\n",
      "        parser=dict(type='LineJsonParser', keys=['filename', 'text'])),\n",
      "    pipeline=None,\n",
      "    test_mode=False)\n",
      "train_list = [\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix='data/mixture/Syn90k/mnt/ramdisk/max/90kDICT32px',\n",
      "        ann_file='data/mixture/Syn90k/label.lmdb',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='lmdb',\n",
      "            parser=dict(type='LineJsonParser', keys=['filename', 'text'])),\n",
      "        pipeline=None,\n",
      "        test_mode=False),\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix=\n",
      "        'data/mixture/SynthText/synthtext/SynthText_patch_horizontal',\n",
      "        ann_file='data/mixture/SynthText/alphanumeric_label.lmdb',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='lmdb',\n",
      "            parser=dict(type='LineJsonParser', keys=['filename', 'text'])),\n",
      "        pipeline=None,\n",
      "        test_mode=False)\n",
      "]\n",
      "test_root = 'data/mixture'\n",
      "test_img_prefix1 = 'data/mixture/IIIT5K/'\n",
      "test_img_prefix2 = 'data/mixture/svt/'\n",
      "test_img_prefix3 = 'data/mixture/icdar_2013/'\n",
      "test_img_prefix4 = 'data/mixture/icdar_2015/'\n",
      "test_img_prefix5 = 'data/mixture/svtp/'\n",
      "test_img_prefix6 = 'data/mixture/ct80/'\n",
      "test_ann_file1 = 'data/mixture/IIIT5K/test_label.txt'\n",
      "test_ann_file2 = 'data/mixture/svt/test_label.txt'\n",
      "test_ann_file3 = 'data/mixture/icdar_2013/test_label_1015.txt'\n",
      "test_ann_file4 = 'data/mixture/icdar_2015/test_label.txt'\n",
      "test_ann_file5 = 'data/mixture/svtp/test_label.txt'\n",
      "test_ann_file6 = 'data/mixture/ct80/test_label.txt'\n",
      "test1 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/IIIT5K/',\n",
      "    ann_file='data/mixture/IIIT5K/test_label.txt',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='txt',\n",
      "        parser=dict(\n",
      "            type='LineStrParser',\n",
      "            keys=['filename', 'text'],\n",
      "            keys_idx=[0, 1],\n",
      "            separator=' ')),\n",
      "    pipeline=None,\n",
      "    test_mode=True)\n",
      "test2 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/svt/',\n",
      "    ann_file='data/mixture/svt/test_label.txt',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='txt',\n",
      "        parser=dict(\n",
      "            type='LineStrParser',\n",
      "            keys=['filename', 'text'],\n",
      "            keys_idx=[0, 1],\n",
      "            separator=' ')),\n",
      "    pipeline=None,\n",
      "    test_mode=True)\n",
      "test3 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/icdar_2013/',\n",
      "    ann_file='data/mixture/icdar_2013/test_label_1015.txt',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='txt',\n",
      "        parser=dict(\n",
      "            type='LineStrParser',\n",
      "            keys=['filename', 'text'],\n",
      "            keys_idx=[0, 1],\n",
      "            separator=' ')),\n",
      "    pipeline=None,\n",
      "    test_mode=True)\n",
      "test4 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/icdar_2015/',\n",
      "    ann_file='data/mixture/icdar_2015/test_label.txt',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='txt',\n",
      "        parser=dict(\n",
      "            type='LineStrParser',\n",
      "            keys=['filename', 'text'],\n",
      "            keys_idx=[0, 1],\n",
      "            separator=' ')),\n",
      "    pipeline=None,\n",
      "    test_mode=True)\n",
      "test5 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/svtp/',\n",
      "    ann_file='data/mixture/svtp/test_label.txt',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='txt',\n",
      "        parser=dict(\n",
      "            type='LineStrParser',\n",
      "            keys=['filename', 'text'],\n",
      "            keys_idx=[0, 1],\n",
      "            separator=' ')),\n",
      "    pipeline=None,\n",
      "    test_mode=True)\n",
      "test6 = dict(\n",
      "    type='OCRDataset',\n",
      "    img_prefix='data/mixture/ct80/',\n",
      "    ann_file='data/mixture/ct80/test_label.txt',\n",
      "    loader=dict(\n",
      "        type='AnnFileLoader',\n",
      "        repeat=1,\n",
      "        file_format='txt',\n",
      "        parser=dict(\n",
      "            type='LineStrParser',\n",
      "            keys=['filename', 'text'],\n",
      "            keys_idx=[0, 1],\n",
      "            separator=' ')),\n",
      "    pipeline=None,\n",
      "    test_mode=True)\n",
      "test_list = [\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix='data/mixture/IIIT5K/',\n",
      "        ann_file='data/mixture/IIIT5K/test_label.txt',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='txt',\n",
      "            parser=dict(\n",
      "                type='LineStrParser',\n",
      "                keys=['filename', 'text'],\n",
      "                keys_idx=[0, 1],\n",
      "                separator=' ')),\n",
      "        pipeline=None,\n",
      "        test_mode=True),\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix='data/mixture/svt/',\n",
      "        ann_file='data/mixture/svt/test_label.txt',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='txt',\n",
      "            parser=dict(\n",
      "                type='LineStrParser',\n",
      "                keys=['filename', 'text'],\n",
      "                keys_idx=[0, 1],\n",
      "                separator=' ')),\n",
      "        pipeline=None,\n",
      "        test_mode=True),\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix='data/mixture/icdar_2013/',\n",
      "        ann_file='data/mixture/icdar_2013/test_label_1015.txt',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='txt',\n",
      "            parser=dict(\n",
      "                type='LineStrParser',\n",
      "                keys=['filename', 'text'],\n",
      "                keys_idx=[0, 1],\n",
      "                separator=' ')),\n",
      "        pipeline=None,\n",
      "        test_mode=True),\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix='data/mixture/icdar_2015/',\n",
      "        ann_file='data/mixture/icdar_2015/test_label.txt',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='txt',\n",
      "            parser=dict(\n",
      "                type='LineStrParser',\n",
      "                keys=['filename', 'text'],\n",
      "                keys_idx=[0, 1],\n",
      "                separator=' ')),\n",
      "        pipeline=None,\n",
      "        test_mode=True),\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix='data/mixture/svtp/',\n",
      "        ann_file='data/mixture/svtp/test_label.txt',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='txt',\n",
      "            parser=dict(\n",
      "                type='LineStrParser',\n",
      "                keys=['filename', 'text'],\n",
      "                keys_idx=[0, 1],\n",
      "                separator=' ')),\n",
      "        pipeline=None,\n",
      "        test_mode=True),\n",
      "    dict(\n",
      "        type='OCRDataset',\n",
      "        img_prefix='data/mixture/ct80/',\n",
      "        ann_file='data/mixture/ct80/test_label.txt',\n",
      "        loader=dict(\n",
      "            type='AnnFileLoader',\n",
      "            repeat=1,\n",
      "            file_format='txt',\n",
      "            parser=dict(\n",
      "                type='LineStrParser',\n",
      "                keys=['filename', 'text'],\n",
      "                keys_idx=[0, 1],\n",
      "                separator=' ')),\n",
      "        pipeline=None,\n",
      "        test_mode=True)\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=192,\n",
      "    workers_per_gpu=8,\n",
      "    val_dataloader=dict(samples_per_gpu=1),\n",
      "    test_dataloader=dict(samples_per_gpu=1),\n",
      "    train=dict(\n",
      "        type='UniformConcatDataset',\n",
      "        datasets=[\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/Syn90k/mnt/ramdisk/max/90kDICT32px',\n",
      "                ann_file='data/mixture/Syn90k/label.lmdb',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='lmdb',\n",
      "                    parser=dict(\n",
      "                        type='LineJsonParser', keys=['filename', 'text'])),\n",
      "                pipeline=None,\n",
      "                test_mode=False),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix=\n",
      "                'data/mixture/SynthText/synthtext/SynthText_patch_horizontal',\n",
      "                ann_file='data/mixture/SynthText/alphanumeric_label.lmdb',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='lmdb',\n",
      "                    parser=dict(\n",
      "                        type='LineJsonParser', keys=['filename', 'text'])),\n",
      "                pipeline=None,\n",
      "                test_mode=False)\n",
      "        ],\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='ResizeOCR',\n",
      "                height=32,\n",
      "                min_width=128,\n",
      "                max_width=128,\n",
      "                keep_aspect_ratio=False,\n",
      "                width_downsample_ratio=0.25),\n",
      "            dict(\n",
      "                type='RandomWrapper',\n",
      "                p=0.5,\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        type='OneOfWrapper',\n",
      "                        transforms=[\n",
      "                            dict(type='RandomRotateTextDet', max_angle=15),\n",
      "                            dict(\n",
      "                                type='TorchVisionWrapper',\n",
      "                                op='RandomAffine',\n",
      "                                degrees=15,\n",
      "                                translate=(0.3, 0.3),\n",
      "                                scale=(0.5, 2.0),\n",
      "                                shear=(-45, 45)),\n",
      "                            dict(\n",
      "                                type='TorchVisionWrapper',\n",
      "                                op='RandomPerspective',\n",
      "                                distortion_scale=0.5,\n",
      "                                p=1)\n",
      "                        ])\n",
      "                ]),\n",
      "            dict(\n",
      "                type='RandomWrapper',\n",
      "                p=0.25,\n",
      "                transforms=[\n",
      "                    dict(type='PyramidRescale'),\n",
      "                    dict(\n",
      "                        type='Albu',\n",
      "                        transforms=[\n",
      "                            dict(type='GaussNoise', var_limit=(20, 20), p=0.5),\n",
      "                            dict(type='MotionBlur', blur_limit=6, p=0.5)\n",
      "                        ])\n",
      "                ]),\n",
      "            dict(\n",
      "                type='RandomWrapper',\n",
      "                p=0.25,\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        type='TorchVisionWrapper',\n",
      "                        op='ColorJitter',\n",
      "                        brightness=0.5,\n",
      "                        saturation=0.5,\n",
      "                        contrast=0.5,\n",
      "                        hue=0.1)\n",
      "                ]),\n",
      "            dict(type='ToTensorOCR'),\n",
      "            dict(\n",
      "                type='NormalizeOCR',\n",
      "                mean=[0.485, 0.456, 0.406],\n",
      "                std=[0.229, 0.224, 0.225]),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                keys=['img'],\n",
      "                meta_keys=[\n",
      "                    'filename', 'ori_shape', 'img_shape', 'text',\n",
      "                    'valid_ratio', 'resize_shape'\n",
      "                ])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='UniformConcatDataset',\n",
      "        datasets=[\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/IIIT5K/',\n",
      "                ann_file='data/mixture/IIIT5K/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/svt/',\n",
      "                ann_file='data/mixture/svt/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/icdar_2013/',\n",
      "                ann_file='data/mixture/icdar_2013/test_label_1015.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/icdar_2015/',\n",
      "                ann_file='data/mixture/icdar_2015/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/svtp/',\n",
      "                ann_file='data/mixture/svtp/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/ct80/',\n",
      "                ann_file='data/mixture/ct80/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True)\n",
      "        ],\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiRotateAugOCR',\n",
      "                rotate_degrees=[0, 90, 270],\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        type='ResizeOCR',\n",
      "                        height=32,\n",
      "                        min_width=128,\n",
      "                        max_width=128,\n",
      "                        keep_aspect_ratio=False,\n",
      "                        width_downsample_ratio=0.25),\n",
      "                    dict(type='ToTensorOCR'),\n",
      "                    dict(\n",
      "                        type='NormalizeOCR',\n",
      "                        mean=[0.485, 0.456, 0.406],\n",
      "                        std=[0.229, 0.224, 0.225]),\n",
      "                    dict(\n",
      "                        type='Collect',\n",
      "                        keys=['img'],\n",
      "                        meta_keys=[\n",
      "                            'filename', 'ori_shape', 'img_shape',\n",
      "                            'valid_ratio', 'resize_shape', 'img_norm_cfg',\n",
      "                            'ori_filename'\n",
      "                        ])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='UniformConcatDataset',\n",
      "        datasets=[\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/IIIT5K/',\n",
      "                ann_file='data/mixture/IIIT5K/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/svt/',\n",
      "                ann_file='data/mixture/svt/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/icdar_2013/',\n",
      "                ann_file='data/mixture/icdar_2013/test_label_1015.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/icdar_2015/',\n",
      "                ann_file='data/mixture/icdar_2015/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/svtp/',\n",
      "                ann_file='data/mixture/svtp/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True),\n",
      "            dict(\n",
      "                type='OCRDataset',\n",
      "                img_prefix='data/mixture/ct80/',\n",
      "                ann_file='data/mixture/ct80/test_label.txt',\n",
      "                loader=dict(\n",
      "                    type='AnnFileLoader',\n",
      "                    repeat=1,\n",
      "                    file_format='txt',\n",
      "                    parser=dict(\n",
      "                        type='LineStrParser',\n",
      "                        keys=['filename', 'text'],\n",
      "                        keys_idx=[0, 1],\n",
      "                        separator=' ')),\n",
      "                pipeline=None,\n",
      "                test_mode=True)\n",
      "        ],\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiRotateAugOCR',\n",
      "                rotate_degrees=[0, 90, 270],\n",
      "                transforms=[\n",
      "                    dict(\n",
      "                        type='ResizeOCR',\n",
      "                        height=32,\n",
      "                        min_width=128,\n",
      "                        max_width=128,\n",
      "                        keep_aspect_ratio=False,\n",
      "                        width_downsample_ratio=0.25),\n",
      "                    dict(type='ToTensorOCR'),\n",
      "                    dict(\n",
      "                        type='NormalizeOCR',\n",
      "                        mean=[0.485, 0.456, 0.406],\n",
      "                        std=[0.229, 0.224, 0.225]),\n",
      "                    dict(\n",
      "                        type='Collect',\n",
      "                        keys=['img'],\n",
      "                        meta_keys=[\n",
      "                            'filename', 'ori_shape', 'img_shape',\n",
      "                            'valid_ratio', 'resize_shape', 'img_norm_cfg',\n",
      "                            'ori_filename'\n",
      "                        ])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='acc')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.work_dir = './work_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?MMOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr = MMOCR(det='DBPP_r50', det_config='', recog='ABINet', recog_config='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # сформируем функцию для показа картинки, так будет удобнее\n",
    "# def show_img(img, resize=(512, 512)):\n",
    "#     # переводим тип массива в unsigned int 8\n",
    "#     # этот тип может представлять числа в диапазоне (0, 255), \n",
    "#     # поэтому он идеален для представления картинок\n",
    "#     img = img.astype(\"uint8\")\n",
    "    \n",
    "#     # если понадобится, то можем изменить размер картинки\n",
    "#     if resize:\n",
    "#         img = cv2.resize(img, resize)\n",
    "\n",
    "#     # составляем картинку из массива и возвращаем её\n",
    "#     # если вызвать эту функции в конце ячейки, то изображении автоматически покажется в ноутбуке\n",
    "#     return Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import mmcv\n",
    "# # import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Train/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['image_path'] == '../Train/train/00015.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['output'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_img = mmcv.imread('../Train/train/15110.jpg')\n",
    "Image.fromarray(predicted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['output'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_img = mmcv.imread('../Train/train/19118.jpg')\n",
    "Image.fromarray(predicted_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:58:50) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0c014dc90ab58d8f57cb62e414ae907c900c1a814f527015429590d621aacac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
